{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6178d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import fastparquet\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import re\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# --- Data Loading and Preprocessing ---\n",
    "def load_and_process_parquet(path):\n",
    "    \"\"\"Load a parquet file and create triplets with correct positive/negative logic.\"\"\"\n",
    "    print(f\"\\nProcessing {path}...\")\n",
    "    df = pd.read_parquet(path, engine='fastparquet')\n",
    "\n",
    "    # Filter for valid rows: keep queries that have at least one passage\n",
    "    valid_mask = (\n",
    "        df['query'].notna() & \n",
    "        df['passages.passage_text'].notna() &\n",
    "        df['passages.passage_text'].apply(lambda x: len(x) > 0 if isinstance(x, list) else False)\n",
    "    )\n",
    "    df = df[valid_mask].reset_index(drop=True)\n",
    "    print(f\"  Found {len(df)} valid queries.\")\n",
    "\n",
    "    # Create a flat list of (query_id, passage) for negative sampling\n",
    "    all_passages = []\n",
    "    for idx, row in df.iterrows():\n",
    "        for p in row['passages.passage_text']:\n",
    "            all_passages.append((idx, p))  # tag with query index for filtering later\n",
    "\n",
    "    triplets = []\n",
    "    for idx, row in df.iterrows():\n",
    "        query = row['query']\n",
    "        query_passages = row['passages.passage_text']\n",
    "\n",
    "        for _ in range(1):  # 10 triplets per query\n",
    "            positive = random.choice(query_passages)\n",
    "\n",
    "            # Negative must be from a *different* query\n",
    "            while True:\n",
    "                neg_query_id, negative = random.choice(all_passages)\n",
    "                if neg_query_id != idx:\n",
    "                    break\n",
    "\n",
    "            triplets.append({'query': query, 'positive': positive, 'negative': negative})\n",
    "\n",
    "    print(f\"  Generated {len(triplets)} triplets.\")\n",
    "    # Convert to list of tuples for TripletDataset\n",
    "    return [(t['query'], t['positive'], t['negative']) for t in triplets]\n",
    "\n",
    "# --- Tokenizer and Vocab ---\n",
    "class PretrainedTokenizer:\n",
    "    def __init__(self, word_to_idx_path):\n",
    "        # Load pretrained word_to_idx mapping\n",
    "        with open(word_to_idx_path, 'rb') as f:\n",
    "            self.word2idx = pickle.load(f)\n",
    "        \n",
    "        print(f\"Loaded vocabulary with {len(self.word2idx):,} tokens\")\n",
    "\n",
    "    def encode(self, sentence):\n",
    "        # Tokenize sentence, preserving punctuation.\n",
    "        tokens = re.findall(r\"\\w+|[.,!?;]\", str(sentence))\n",
    "        # Only include words that exist in vocabulary, skip unknown words\n",
    "        return [self.word2idx[word] for word in tokens if word in self.word2idx]\n",
    "\n",
    "    def vocab_size(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "# --- Dataset Class ---\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query, pos_doc, neg_doc = self.data[idx]\n",
    "        return (torch.tensor(self.tokenizer.encode(query), dtype=torch.long),\n",
    "                torch.tensor(self.tokenizer.encode(pos_doc), dtype=torch.long),\n",
    "                torch.tensor(self.tokenizer.encode(neg_doc), dtype=torch.long))\n",
    "\n",
    "# --- Collate Function ---\n",
    "def collate_fn(batch):\n",
    "    queries, pos_docs, neg_docs = zip(*batch)\n",
    "    return (\n",
    "        pad_sequence(queries, batch_first=True, padding_value=0),\n",
    "        pad_sequence(pos_docs, batch_first=True, padding_value=0),\n",
    "        pad_sequence(neg_docs, batch_first=True, padding_value=0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35ca90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocabulary with 400,000 tokens\n",
      "\n",
      "Creating DataLoaders...\n",
      "\n",
      "Processing ../data/ms_marco_train.parquet...\n",
      "  Found 808731 valid queries.\n",
      "  Generated 808731 triplets.\n",
      "✅ train dataloader ready!\n",
      "\n",
      "Processing ../data/ms_marco_validation.parquet...\n",
      "  Found 101093 valid queries.\n",
      "  Generated 101093 triplets.\n",
      "✅ validation dataloader ready!\n",
      "\n",
      "Processing ../data/ms_marco_test.parquet...\n",
      "  Found 101092 valid queries.\n",
      "  Generated 101092 triplets.\n",
      "✅ test dataloader ready!\n",
      "\n",
      "Dataset sizes:\n",
      "  Training: 808,731 triplets\n",
      "  Validation: 101,093 triplets\n",
      "  Test: 101,092 triplets\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained tokenizer\n",
    "tokenizer = PretrainedTokenizer('../data/word_to_idx.pkl')\n",
    "\n",
    "# Dataset paths\n",
    "dataset_paths = {\n",
    "    'train': '../data/ms_marco_train.parquet',\n",
    "    'validation': '../data/ms_marco_validation.parquet',\n",
    "    'test': '../data/ms_marco_test.parquet'\n",
    "}\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "dataloaders = {}\n",
    "datasets = {}\n",
    "\n",
    "print(\"\\nCreating DataLoaders...\")\n",
    "for split, path in dataset_paths.items():\n",
    "    data_tuples = load_and_process_parquet(path)\n",
    "    datasets[split] = TripletDataset(data_tuples, tokenizer)\n",
    "    \n",
    "    # Use a smaller batch size for validation and test if needed\n",
    "    batch_size = 20 # You can adjust this\n",
    "\n",
    "    dataloaders[split] = DataLoader(\n",
    "        datasets[split],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(split == 'train'),\n",
    "        num_workers=2,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    print(f\"✅ {split} dataloader ready!\")\n",
    "\n",
    "# Extract data for later use (e.g., evaluation)\n",
    "train_data = datasets['train'].data\n",
    "val_data = datasets['validation'].data\n",
    "test_data = datasets['test'].data\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Training: {len(train_data):,} triplets\")\n",
    "print(f\"  Validation: {len(val_data):,} triplets\")\n",
    "print(f\"  Test: {len(test_data):,} triplets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b3c19fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training triplet:\n",
      "Query: )what was the immediate impact of the success of the manhattan project?...\n",
      "Positive: The Manhattan Project. This once classified photograph features the first atomic bomb — a weapon tha...\n",
      "Negative: Muscle twitching, also known as muscle fasciculation, is marked by small muscle contractions in the ...\n",
      "\n",
      "Dataset sizes:\n",
      "  Training: 8,087,310 triplets\n",
      "  Validation: 1,010,930 triplets\n",
      "  Test: 1,010,920 triplets\n"
     ]
    }
   ],
   "source": [
    "# Test the training dataloader\n",
    "train_loader = dataloaders['train']\n",
    "\n",
    "print(f\"📊 Dataset Info:\")\n",
    "print(f\"  Total batches in train: {len(train_loader)}\")\n",
    "print(f\"  Batch size: {train_loader.batch_size}\")\n",
    "\n",
    "print(\"\\n🔍 Testing first few batches...\")\n",
    "for batch_idx, (query_batch, pos_batch, neg_batch) in enumerate(train_loader):\n",
    "    print(f\"\\nBatch {batch_idx + 1}:\")\n",
    "    print(f\"  Query batch shape: {query_batch.shape}\")\n",
    "    print(f\"  Positive batch shape: {pos_batch.shape}\")\n",
    "    print(f\"  Negative batch shape: {neg_batch.shape}\")\n",
    "    \n",
    "    if batch_idx >= 3:  # Just show first 4 batches\n",
    "        break\n",
    "\n",
    "print(\"\\n✅ DataLoader test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d19900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Dual RNN Encoder Model ---\n",
    "class RNNEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, pretrained_embeddings=None):\n",
    "        super().__init__()\n",
    "        # Use padding_idx=0 since we pad with 0\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        # Load pretrained embeddings if provided\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "            # Keep embeddings trainable (they are by default)\n",
    "            \n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, h_n = self.rnn(x)\n",
    "        return h_n.squeeze(0)  # shape: (batch, hidden_dim)\n",
    "\n",
    "# --- Triplet Loss Function ---\n",
    "def triplet_loss_function(triplet, distance_function, margin):\n",
    "    query, pos_doc, neg_doc = triplet\n",
    "    d_pos = distance_function(query, pos_doc)\n",
    "    d_neg = distance_function(query, neg_doc)\n",
    "    return torch.clamp(d_pos - d_neg + margin, min=0.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea44b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocabulary with 400,000 tokens\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained tokenizer\n",
    "tokenizer = PretrainedTokenizer('../data/word_to_idx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ba67ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained embeddings: (400000, 200)\n",
      "Vocabulary size: 400000\n",
      "Embedding dimension: 200\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open('../backend/config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# --- Training Setup ---\n",
    "VOCAB_SIZE = tokenizer.vocab_size()\n",
    "\n",
    "# Load pretrained embeddings\n",
    "pretrained_embeddings = np.load('../data/embeddings.npy')\n",
    "EMBED_DIM = pretrained_embeddings.shape[1]  # Get embedding dimension from loaded embeddings\n",
    "\n",
    "print(f\"Loaded pretrained embeddings: {pretrained_embeddings.shape}\")\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "print(f\"Embedding dimension: {EMBED_DIM}\")\n",
    "\n",
    "# Enhanced device selection with better fallback handling\n",
    "def get_best_device():\n",
    "    \"\"\"Get the best available device with informative feedback.\"\"\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"✅ MPS (Apple Silicon GPU) is available and will be used\")\n",
    "        return torch.device('mps')\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"✅ CUDA GPU is available and will be used\")\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        print(\"⚠️  No GPU acceleration available - using CPU\")\n",
    "        print(\"   💡 For better performance on Apple Silicon, run outside Docker\")\n",
    "        print(\"   💡 For CUDA support, configure Docker with GPU passthrough\")\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_best_device()\n",
    "print(f\"Selected device: {device}\")\n",
    "\n",
    "# Initialize encoders with pretrained embeddings and move to GPU\n",
    "query_encoder = RNNEncoder(VOCAB_SIZE, EMBED_DIM, config['HIDDEN_DIM'], pretrained_embeddings).to(device)\n",
    "doc_encoder = RNNEncoder(VOCAB_SIZE, EMBED_DIM, config['HIDDEN_DIM'], pretrained_embeddings).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(list(query_encoder.parameters()) + list(doc_encoder.parameters()), lr=config['LR'])\n",
    "\n",
    "# The dataloader is already created, we just need to adjust batch size in the config\n",
    "# and re-run the dataloader creation cell if we want to change it.\n",
    "config['BATCH_SIZE'] = dataloaders['train'].batch_size\n",
    "train_loader = dataloaders['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800f97dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting training...\n",
      "  Batch 50/40437, Loss: 0.9845\n",
      "  Batch 100/40437, Loss: 0.9728\n",
      "  Batch 150/40437, Loss: 1.0223\n",
      "  Batch 200/40437, Loss: 0.9979\n",
      "  Batch 250/40437, Loss: 0.9010\n",
      "  Batch 300/40437, Loss: 1.2162\n",
      "  Batch 350/40437, Loss: 0.8343\n",
      "  Batch 400/40437, Loss: 0.8473\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m triplet_loss_function((q_vec, pos_vec, neg_vec), F\u001b[38;5;241m.\u001b[39mpairwise_distance, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMARGIN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "import time\n",
    "\n",
    "print(\"🚀 Starting training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config['EPOCHS']):\n",
    "    epoch_start = time.time()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for query_batch, pos_batch, neg_batch in train_loader:\n",
    "        # Move tensors to GPU\n",
    "        query_batch = query_batch.to(device)\n",
    "        pos_batch = pos_batch.to(device)\n",
    "        neg_batch = neg_batch.to(device)\n",
    "        \n",
    "        q_vec = query_encoder(query_batch)\n",
    "        pos_vec = doc_encoder(pos_batch)\n",
    "        neg_vec = doc_encoder(neg_batch)\n",
    "\n",
    "        loss = triplet_loss_function((q_vec, pos_vec, neg_vec), F.pairwise_distance, config['MARGIN'])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Progress indicator every 50 batches\n",
    "        if num_batches % 50 == 0:\n",
    "            print(f\"  Batch {num_batches}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}/{config['EPOCHS']}, Avg Loss: {avg_loss:.4f}, Time: {epoch_time:.1f}s\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n✅ Training completed! Total time: {total_time/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23204e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Automatic Model Saving ---\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create artifacts directory\n",
    "artifacts_dir = \"../artifacts\"\n",
    "os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "# Create timestamped run directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = os.path.join(artifacts_dir, f\"two_tower_run_{timestamp}\")\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "print(f\"💾 Saving artifacts to: {run_dir}\")\n",
    "\n",
    "# Save model state dictionaries\n",
    "torch.save({\n",
    "    'query_encoder_state_dict': query_encoder.state_dict(),\n",
    "    'doc_encoder_state_dict': doc_encoder.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': config['EPOCHS'],\n",
    "    'final_loss': avg_loss\n",
    "}, os.path.join(run_dir, 'model_checkpoint.pth'))\n",
    "\n",
    "# Save model architectures (for easy loading later)\n",
    "torch.save(query_encoder, os.path.join(run_dir, 'query_encoder_full.pth'))\n",
    "torch.save(doc_encoder, os.path.join(run_dir, 'doc_encoder_full.pth'))\n",
    "\n",
    "# Save training configuration\n",
    "training_config = {\n",
    "    'model_config': {\n",
    "        'vocab_size': VOCAB_SIZE,\n",
    "        'embed_dim': EMBED_DIM,\n",
    "        'hidden_dim': config['HIDDEN_DIM'],\n",
    "        'margin': config['MARGIN']\n",
    "    },\n",
    "    'training_config': {\n",
    "        'epochs': config['EPOCHS'],\n",
    "        'batch_size': config['BATCH_SIZE'],\n",
    "        'learning_rate': config['LR'],\n",
    "        'device': str(device)\n",
    "    },\n",
    "    'data_config': {\n",
    "        'train_samples': len(train_data),\n",
    "        'val_samples': len(val_data),\n",
    "        'test_samples': len(test_data),\n",
    "        'total_triplets': len(train_data) + len(val_data) + len(test_data)\n",
    "    },\n",
    "    'training_results': {\n",
    "        'final_avg_loss': avg_loss\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_dir, 'training_config.json'), 'w') as f:\n",
    "    json.dump(training_config, f, indent=2)\n",
    "\n",
    "# Save tokenizer (copy the word2idx file or save the object)\n",
    "import shutil\n",
    "if os.path.exists(config['WORD_TO_IDX_PATH']):\n",
    "    shutil.copy2(config['WORD_TO_IDX_PATH'], os.path.join(run_dir, 'word_to_idx.pkl'))\n",
    "\n",
    "print(f\"✅ Saved artifacts:\")\n",
    "print(f\"  📁 Directory: {run_dir}\")\n",
    "print(f\"  🧠 Models: model_checkpoint.pth, *_encoder_full.pth\")\n",
    "print(f\"  ⚙️  Config: training_config.json\")\n",
    "print(f\"  📝 Tokenizer: word_to_idx.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b53d060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained embeddings: (400000, 200)\n",
      "Vocabulary size: 400000\n",
      "Embedding dimension: 200\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- MPS-Optimized Inference Function ---\n",
    "def search(query_text, documents, tokenizer, query_encoder, doc_encoder):\n",
    "    \"\"\"\n",
    "    Search function optimized for MPS (Apple Silicon GPU)\n",
    "    \"\"\"\n",
    "    # Get device from encoder\n",
    "    device = next(query_encoder.parameters()).device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Encode query and move to device\n",
    "        query_tensor = pad_sequence([torch.tensor(tokenizer.encode(query_text), dtype=torch.long)], batch_first=True).to(device)\n",
    "        query_vec = query_encoder(query_tensor)\n",
    "\n",
    "        # Encode documents and move to device\n",
    "        doc_tensors = pad_sequence([torch.tensor(tokenizer.encode(doc), dtype=torch.long) for doc in documents], batch_first=True).to(device)\n",
    "        doc_vecs = doc_encoder(doc_tensors)\n",
    "\n",
    "        # Calculate similarity scores\n",
    "        scores = F.cosine_similarity(query_vec, doc_vecs)\n",
    "        top_indices = torch.argsort(scores, descending=True)\n",
    "        \n",
    "        # Convert results back to CPU for return (if needed)\n",
    "        results = [(documents[i], scores[i].item()) for i in top_indices]\n",
    "        \n",
    "        # Clear MPS cache after inference if available\n",
    "        if device.type == 'mps' and hasattr(torch.mps, 'empty_cache'):\n",
    "            torch.mps.empty_cache()\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea93713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting training...\n",
      "  Batch 50/126365, Loss: 1.0012\n",
      "  Batch 100/126365, Loss: 0.9825\n"
     ]
    }
   ],
   "source": [
    "# --- Comprehensive Testing with Real Data ---\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def evaluate_retrieval(test_data, query_encoder, doc_encoder, tokenizer, k=10):\n",
    "    \"\"\"\n",
    "    Evaluate retrieval performance using real test data\n",
    "    \"\"\"\n",
    "    print(\"🔍 COMPREHENSIVE RETRIEVAL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Group test data by query to get all relevant docs per query\n",
    "    query_to_docs = defaultdict(list)\n",
    "    for query, pos_doc, neg_doc in test_data[:100]:  # Sample 100 for speed\n",
    "        query_to_docs[query].extend([pos_doc, neg_doc])\n",
    "    \n",
    "    # Test multiple queries\n",
    "    sample_queries = list(query_to_docs.keys())[:5]  # Test 5 queries\n",
    "    \n",
    "    for i, query in enumerate(sample_queries):\n",
    "        print(f\"\\n🔎 TEST QUERY {i+1}: {query[:100]}...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Get all documents for this query\n",
    "        documents = query_to_docs[query]\n",
    "        \n",
    "        # Add some random documents from other queries for harder test\n",
    "        other_docs = []\n",
    "        for other_query in random.sample(list(query_to_docs.keys()), 3):\n",
    "            if other_query != query:\n",
    "                other_docs.extend(query_to_docs[other_query][:2])\n",
    "        \n",
    "        all_documents = documents + other_docs\n",
    "        random.shuffle(all_documents)\n",
    "        \n",
    "        print(f\"📚 Searching through {len(all_documents)} documents...\")\n",
    "        \n",
    "        # Run search\n",
    "        results = search(query, all_documents, tokenizer, query_encoder, doc_encoder)\n",
    "        \n",
    "        print(f\"\\n🏆 TOP {min(3, len(results))} RESULTS:\")\n",
    "        for j, (doc, score) in enumerate(results[:3]):\n",
    "            relevance = \"✅ RELEVANT\" if doc in documents else \"❌ NOT RELEVANT\"\n",
    "            print(f\"{j+1}. Score: {score:.4f} {relevance}\")\n",
    "            print(f\"   Doc: {doc[:80]}...\")\n",
    "            print()\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "evaluate_retrieval(test_data, query_encoder, doc_encoder, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Automatic Model Saving ---\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create artifacts directory\n",
    "artifacts_dir = \"../artifacts\"\n",
    "os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "# Create timestamped run directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = os.path.join(artifacts_dir, f\"two_tower_run_{timestamp}\")\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "print(f\"💾 Saving artifacts to: {run_dir}\")\n",
    "\n",
    "# Save model state dictionaries\n",
    "torch.save({\n",
    "    'query_encoder_state_dict': query_encoder.state_dict(),\n",
    "    'doc_encoder_state_dict': doc_encoder.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': config['EPOCHS'],\n",
    "    'final_loss': avg_loss\n",
    "}, os.path.join(run_dir, 'model_checkpoint.pth'))\n",
    "\n",
    "# Save model architectures (for easy loading later)\n",
    "torch.save(query_encoder, os.path.join(run_dir, 'query_encoder_full.pth'))\n",
    "torch.save(doc_encoder, os.path.join(run_dir, 'doc_encoder_full.pth'))\n",
    "\n",
    "# Save training configuration\n",
    "training_config = {\n",
    "    'model_config': {\n",
    "        'vocab_size': VOCAB_SIZE,\n",
    "        'embed_dim': EMBED_DIM,\n",
    "        'hidden_dim': config['HIDDEN_DIM'],\n",
    "        'margin': config['MARGIN']\n",
    "    },\n",
    "    'training_config': {\n",
    "        'epochs': config['EPOCHS'],\n",
    "        'batch_size': config['BATCH_SIZE'],\n",
    "        'learning_rate': config['LR'],\n",
    "        'device': str(device)\n",
    "    },\n",
    "    'data_config': {\n",
    "        'train_samples': len(train_data),\n",
    "        'val_samples': len(val_data),\n",
    "        'test_samples': len(test_data),\n",
    "        'total_triplets': len(train_data) + len(val_data) + len(test_data)\n",
    "    },\n",
    "    'training_results': {\n",
    "        'final_avg_loss': avg_loss\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_dir, 'training_config.json'), 'w') as f:\n",
    "    json.dump(training_config, f, indent=2)\n",
    "\n",
    "# Save tokenizer (copy the word2idx file or save the object)\n",
    "import shutil\n",
    "if os.path.exists(config['WORD_TO_IDX_PATH']):\n",
    "    shutil.copy2(config['WORD_TO_IDX_PATH'], os.path.join(run_dir, 'word_to_idx.pkl'))\n",
    "\n",
    "print(f\"✅ Saved artifacts:\")\n",
    "print(f\"  📁 Directory: {run_dir}\")\n",
    "print(f\"  🧠 Models: model_checkpoint.pth, *_encoder_full.pth\")\n",
    "print(f\"  ⚙️  Config: training_config.json\")\n",
    "print(f\"  📝 Tokenizer: word_to_idx.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1362865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MPS-Optimized Inference Function ---\n",
    "def search(query_text, documents, tokenizer, query_encoder, doc_encoder):\n",
    "    \"\"\"\n",
    "    Search function optimized for MPS (Apple Silicon GPU)\n",
    "    \"\"\"\n",
    "    # Get device from encoder\n",
    "    device = next(query_encoder.parameters()).device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Encode query and move to device\n",
    "        query_tensor = pad_sequence([torch.tensor(tokenizer.encode(query_text), dtype=torch.long)], batch_first=True).to(device)\n",
    "        query_vec = query_encoder(query_tensor)\n",
    "\n",
    "        # Encode documents and move to device\n",
    "        doc_tensors = pad_sequence([torch.tensor(tokenizer.encode(doc), dtype=torch.long) for doc in documents], batch_first=True).to(device)\n",
    "        doc_vecs = doc_encoder(doc_tensors)\n",
    "\n",
    "        # Calculate similarity scores\n",
    "        scores = F.cosine_similarity(query_vec, doc_vecs)\n",
    "        top_indices = torch.argsort(scores, descending=True)\n",
    "        \n",
    "        # Convert results back to CPU for return (if needed)\n",
    "        results = [(documents[i], scores[i].item()) for i in top_indices]\n",
    "        \n",
    "        # Clear MPS cache after inference if available\n",
    "        if device.type == 'mps' and hasattr(torch.mps, 'empty_cache'):\n",
    "            torch.mps.empty_cache()\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448019c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Comprehensive Testing with Real Data ---\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def evaluate_retrieval(test_data, query_encoder, doc_encoder, tokenizer, k=10):\n",
    "    \"\"\"\n",
    "    Evaluate retrieval performance using real test data\n",
    "    \"\"\"\n",
    "    print(\"🔍 COMPREHENSIVE RETRIEVAL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Group test data by query to get all relevant docs per query\n",
    "    query_to_docs = defaultdict(list)\n",
    "    for query, pos_doc, neg_doc in test_data[:100]:  # Sample 100 for speed\n",
    "        query_to_docs[query].extend([pos_doc, neg_doc])\n",
    "    \n",
    "    # Test multiple queries\n",
    "    sample_queries = list(query_to_docs.keys())[:5]  # Test 5 queries\n",
    "    \n",
    "    for i, query in enumerate(sample_queries):\n",
    "        print(f\"\\n🔎 TEST QUERY {i+1}: {query[:100]}...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Get all documents for this query\n",
    "        documents = query_to_docs[query]\n",
    "        \n",
    "        # Add some random documents from other queries for harder test\n",
    "        other_docs = []\n",
    "        for other_query in random.sample(list(query_to_docs.keys()), 3):\n",
    "            if other_query != query:\n",
    "                other_docs.extend(query_to_docs[other_query][:2])\n",
    "        \n",
    "        all_documents = documents + other_docs\n",
    "        random.shuffle(all_documents)\n",
    "        \n",
    "        print(f\"📚 Searching through {len(all_documents)} documents...\")\n",
    "        \n",
    "        # Run search\n",
    "        results = search(query, all_documents, tokenizer, query_encoder, doc_encoder)\n",
    "        \n",
    "        print(f\"\\n🏆 TOP {min(3, len(results))} RESULTS:\")\n",
    "        for j, (doc, score) in enumerate(results[:3]):\n",
    "            relevance = \"✅ RELEVANT\" if doc in documents else \"❌ NOT RELEVANT\"\n",
    "            print(f\"{j+1}. Score: {score:.4f} {relevance}\")\n",
    "            print(f\"   Doc: {doc[:80]}...\")\n",
    "            print()\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "evaluate_retrieval(test_data, query_encoder, doc_encoder, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac337bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
