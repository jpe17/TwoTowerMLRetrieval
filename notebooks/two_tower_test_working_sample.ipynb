{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c4c46c",
   "metadata": {},
   "source": [
    "### **Step 1**: Import configs and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6178d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import fastparquet\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import re\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "# --- Data Loading and Preprocessing ---\n",
    "def load_and_process_parquet(path):\n",
    "    \"\"\"Load a parquet file and create triplets with correct positive/negative logic.\"\"\"\n",
    "    print(f\"\\nProcessing {path}...\")\n",
    "    df = pd.read_parquet(path, engine='fastparquet')\n",
    "\n",
    "    # Filter for valid rows: keep queries that have at least one passage\n",
    "    valid_mask = (\n",
    "        df['query'].notna() & \n",
    "        df['passages.passage_text'].notna() &\n",
    "        df['passages.passage_text'].apply(lambda x: len(x) > 0 if isinstance(x, list) else False)\n",
    "    )\n",
    "    df = df[valid_mask].reset_index(drop=True)\n",
    "    print(f\"  Found {len(df)} valid queries.\")\n",
    "\n",
    "    # Create a flat list of (query_id, passage) for negative sampling\n",
    "    all_passages = []\n",
    "    for idx, row in df.iterrows():\n",
    "        for p in row['passages.passage_text']:\n",
    "            all_passages.append((idx, p))  # tag with query index for filtering later\n",
    "\n",
    "    triplets = []\n",
    "    for idx, row in df.iterrows():\n",
    "        query = row['query']\n",
    "        query_passages = row['passages.passage_text']\n",
    "\n",
    "        for _ in range(1):  # 10 triplets per query\n",
    "            positive = random.choice(query_passages)\n",
    "\n",
    "            # Negative must be from a *different* query\n",
    "            while True:\n",
    "                neg_query_id, negative = random.choice(all_passages)\n",
    "                if neg_query_id != idx:\n",
    "                    break\n",
    "\n",
    "            triplets.append({'query': query, 'positive': positive, 'negative': negative})\n",
    "\n",
    "    print(f\"  Generated {len(triplets)} triplets.\")\n",
    "    # Convert to list of tuples for TripletDataset\n",
    "    return [(t['query'], t['positive'], t['negative']) for t in triplets]\n",
    "\n",
    "# --- Tokenizer and Vocab ---\n",
    "class PretrainedTokenizer:\n",
    "    def __init__(self, word_to_idx_path):\n",
    "        # Load pretrained word_to_idx mapping\n",
    "        with open(word_to_idx_path, 'rb') as f:\n",
    "            self.word2idx = pickle.load(f)\n",
    "        \n",
    "        print(f\"Loaded vocabulary with {len(self.word2idx):,} tokens\")\n",
    "\n",
    "    def encode(self, sentence):\n",
    "        # Tokenize sentence, preserving punctuation.\n",
    "        tokens = re.findall(r\"\\w+|[.,!?;]\", str(sentence))\n",
    "        # Only include words that exist in vocabulary, skip unknown words\n",
    "        return [self.word2idx[word] for word in tokens if word in self.word2idx]\n",
    "\n",
    "    def vocab_size(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "# --- Dataset Class ---\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query, pos_doc, neg_doc = self.data[idx]\n",
    "        return (torch.tensor(self.tokenizer.encode(query), dtype=torch.long),\n",
    "                torch.tensor(self.tokenizer.encode(pos_doc), dtype=torch.long),\n",
    "                torch.tensor(self.tokenizer.encode(neg_doc), dtype=torch.long))\n",
    "\n",
    "# --- Collate Function ---\n",
    "def collate_fn(batch):\n",
    "    queries, pos_docs, neg_docs = zip(*batch)\n",
    "    return (\n",
    "        pad_sequence(queries, batch_first=True, padding_value=0),\n",
    "        pad_sequence(pos_docs, batch_first=True, padding_value=0),\n",
    "        pad_sequence(neg_docs, batch_first=True, padding_value=0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf147174",
   "metadata": {},
   "source": [
    "### **Step 2**: Process data to get triplets for train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ca90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocabulary with 400,000 tokens\n",
      "\n",
      "Creating DataLoaders...\n",
      "\n",
      "Processing ../data/ms_marco_train.parquet...\n",
      "  Found 808731 valid queries.\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained tokenizer\n",
    "tokenizer = PretrainedTokenizer('../data/word_to_idx.pkl')\n",
    "\n",
    "# Dataset paths\n",
    "dataset_paths = {\n",
    "    'train': '../data/ms_marco_train.parquet',\n",
    "    'validation': '../data/ms_marco_validation.parquet',\n",
    "    'test': '../data/ms_marco_test.parquet'\n",
    "}\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "dataloaders = {}\n",
    "datasets = {}\n",
    "\n",
    "print(\"\\nCreating DataLoaders...\")\n",
    "for split, path in dataset_paths.items():\n",
    "    data_tuples = load_and_process_parquet(path)\n",
    "    datasets[split] = TripletDataset(data_tuples, tokenizer)\n",
    "    \n",
    "    # Use a smaller batch size for validation and test if needed\n",
    "    batch_size = 20 # You can adjust this\n",
    "\n",
    "    dataloaders[split] = DataLoader(\n",
    "        datasets[split],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(split == 'train'),\n",
    "        num_workers=2,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    print(f\"‚úÖ {split} dataloader ready!\")\n",
    "\n",
    "# Extract data for later use (e.g., evaluation)\n",
    "train_data = datasets['train'].data\n",
    "val_data = datasets['validation'].data\n",
    "test_data = datasets['test'].data\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Training: {len(train_data):,} triplets\")\n",
    "print(f\"  Validation: {len(val_data):,} triplets\")\n",
    "print(f\"  Test: {len(test_data):,} triplets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a44619a",
   "metadata": {},
   "source": [
    "### **Step 3**: Select sub-sample triplets for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b3c19fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training triplet:\n",
      "Query: )what was the immediate impact of the success of the manhattan project?...\n",
      "Positive: The Manhattan Project. This once classified photograph features the first atomic bomb ‚Äî a weapon tha...\n",
      "Negative: Muscle twitching, also known as muscle fasciculation, is marked by small muscle contractions in the ...\n",
      "\n",
      "Dataset sizes:\n",
      "  Training: 8,087,310 triplets\n",
      "  Validation: 1,010,930 triplets\n",
      "  Test: 1,010,920 triplets\n"
     ]
    }
   ],
   "source": [
    "# Test the training dataloader\n",
    "train_loader = dataloaders['train']\n",
    "\n",
    "print(f\"üìä Dataset Info:\")\n",
    "print(f\"  Total batches in train: {len(train_loader)}\")\n",
    "print(f\"  Batch size: {train_loader.batch_size}\")\n",
    "\n",
    "print(\"\\nüîç Testing first few batches...\")\n",
    "for batch_idx, (query_batch, pos_batch, neg_batch) in enumerate(train_loader):\n",
    "    print(f\"\\nBatch {batch_idx + 1}:\")\n",
    "    print(f\"  Query batch shape: {query_batch.shape}\")\n",
    "    print(f\"  Positive batch shape: {pos_batch.shape}\")\n",
    "    print(f\"  Negative batch shape: {neg_batch.shape}\")\n",
    "    \n",
    "    if batch_idx >= 3:  # Just show first 4 batches\n",
    "        break\n",
    "\n",
    "print(\"\\n‚úÖ DataLoader test completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e92a1",
   "metadata": {},
   "source": [
    "### **Step 4**: Select sub-sample triplets for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d19900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Dual RNN Encoder Model ---\n",
    "class RNNEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, pretrained_embeddings=None):\n",
    "        super().__init__()\n",
    "        # Use padding_idx=0 since we pad with 0\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        # Load pretrained embeddings if provided\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "            # Keep embeddings trainable (they are by default)\n",
    "            \n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, h_n = self.rnn(x)\n",
    "        return h_n.squeeze(0)  # shape: (batch, hidden_dim)\n",
    "\n",
    "# --- Triplet Loss Function ---\n",
    "def triplet_loss_function(triplet, distance_function, margin):\n",
    "    query, pos_doc, neg_doc = triplet\n",
    "    d_pos = distance_function(query, pos_doc)\n",
    "    d_neg = distance_function(query, neg_doc)\n",
    "    return torch.clamp(d_pos - d_neg + margin, min=0.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eea44b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocabulary with 400,000 tokens\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained tokenizer\n",
    "tokenizer = PretrainedTokenizer('../data/word_to_idx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3ba67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open('../backend/config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# --- Training Setup ---\n",
    "VOCAB_SIZE = tokenizer.vocab_size()\n",
    "\n",
    "# Load pretrained embeddings\n",
    "pretrained_embeddings = np.load('../data/embeddings.npy')\n",
    "EMBED_DIM = pretrained_embeddings.shape[1]  # Get embedding dimension from loaded embeddings\n",
    "\n",
    "print(f\"Loaded pretrained embeddings: {pretrained_embeddings.shape}\")\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "print(f\"Embedding dimension: {EMBED_DIM}\")\n",
    "\n",
    "# Check if MPS is available and set device\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize encoders with pretrained embeddings and move to GPU\n",
    "query_encoder = RNNEncoder(VOCAB_SIZE, EMBED_DIM, config['HIDDEN_DIM'], pretrained_embeddings).to(device)\n",
    "doc_encoder = RNNEncoder(VOCAB_SIZE, EMBED_DIM, config['HIDDEN_DIM'], pretrained_embeddings).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(list(query_encoder.parameters()) + list(doc_encoder.parameters()), lr=config['LR'])\n",
    "\n",
    "# The dataloader is already created, we just need to adjust batch size in the config\n",
    "# and re-run the dataloader creation cell if we want to change it.\n",
    "config['BATCH_SIZE'] = dataloaders['train'].batch_size\n",
    "train_loader = dataloaders['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Loop ---\n",
    "import time\n",
    "\n",
    "print(\"üöÄ Starting training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config['EPOCHS']):\n",
    "    epoch_start = time.time()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for query_batch, pos_batch, neg_batch in train_loader:\n",
    "        # Move tensors to GPU\n",
    "        query_batch = query_batch.to(device)\n",
    "        pos_batch = pos_batch.to(device)\n",
    "        neg_batch = neg_batch.to(device)\n",
    "        \n",
    "        q_vec = query_encoder(query_batch)\n",
    "        pos_vec = doc_encoder(pos_batch)\n",
    "        neg_vec = doc_encoder(neg_batch)\n",
    "\n",
    "        loss = triplet_loss_function((q_vec, pos_vec, neg_vec), F.pairwise_distance, config['MARGIN'])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Progress indicator every 50 batches\n",
    "        if num_batches % 50 == 0:\n",
    "            print(f\"  Batch {num_batches}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}/{config['EPOCHS']}, Avg Loss: {avg_loss:.4f}, Time: {epoch_time:.1f}s\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training completed! Total time: {total_time/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23204e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Automatic Model Saving ---\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create artifacts directory\n",
    "artifacts_dir = \"../artifacts\"\n",
    "os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "# Create timestamped run directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = os.path.join(artifacts_dir, f\"two_tower_run_{timestamp}\")\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üíæ Saving artifacts to: {run_dir}\")\n",
    "\n",
    "# Save model state dictionaries\n",
    "torch.save({\n",
    "    'query_encoder_state_dict': query_encoder.state_dict(),\n",
    "    'doc_encoder_state_dict': doc_encoder.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': config['EPOCHS'],\n",
    "    'final_loss': avg_loss\n",
    "}, os.path.join(run_dir, 'model_checkpoint.pth'))\n",
    "\n",
    "# Save model architectures (for easy loading later)\n",
    "torch.save(query_encoder, os.path.join(run_dir, 'query_encoder_full.pth'))\n",
    "torch.save(doc_encoder, os.path.join(run_dir, 'doc_encoder_full.pth'))\n",
    "\n",
    "# Save training configuration\n",
    "training_config = {\n",
    "    'model_config': {\n",
    "        'vocab_size': VOCAB_SIZE,\n",
    "        'embed_dim': EMBED_DIM,\n",
    "        'hidden_dim': config['HIDDEN_DIM'],\n",
    "        'margin': config['MARGIN']\n",
    "    },\n",
    "    'training_config': {\n",
    "        'epochs': config['EPOCHS'],\n",
    "        'batch_size': config['BATCH_SIZE'],\n",
    "        'learning_rate': config['LR'],\n",
    "        'device': str(device)\n",
    "    },\n",
    "    'data_config': {\n",
    "        'train_samples': len(train_data),\n",
    "        'val_samples': len(val_data),\n",
    "        'test_samples': len(test_data),\n",
    "        'total_triplets': len(train_data) + len(val_data) + len(test_data)\n",
    "    },\n",
    "    'training_results': {\n",
    "        'final_avg_loss': avg_loss\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_dir, 'training_config.json'), 'w') as f:\n",
    "    json.dump(training_config, f, indent=2)\n",
    "\n",
    "# Save tokenizer (copy the word2idx file or save the object)\n",
    "import shutil\n",
    "if os.path.exists(config['WORD_TO_IDX_PATH']):\n",
    "    shutil.copy2(config['WORD_TO_IDX_PATH'], os.path.join(run_dir, 'word_to_idx.pkl'))\n",
    "\n",
    "print(f\"‚úÖ Saved artifacts:\")\n",
    "print(f\"  üìÅ Directory: {run_dir}\")\n",
    "print(f\"  üß† Models: model_checkpoint.pth, *_encoder_full.pth\")\n",
    "print(f\"  ‚öôÔ∏è  Config: training_config.json\")\n",
    "print(f\"  üìù Tokenizer: word_to_idx.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b53d060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained embeddings: (400000, 200)\n",
      "Vocabulary size: 400000\n",
      "Embedding dimension: 200\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- MPS-Optimized Inference Function ---\n",
    "def search(query_text, documents, tokenizer, query_encoder, doc_encoder):\n",
    "    \"\"\"\n",
    "    Search function optimized for MPS (Apple Silicon GPU)\n",
    "    \"\"\"\n",
    "    # Get device from encoder\n",
    "    device = next(query_encoder.parameters()).device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Encode query and move to device\n",
    "        query_tensor = pad_sequence([torch.tensor(tokenizer.encode(query_text), dtype=torch.long)], batch_first=True).to(device)\n",
    "        query_vec = query_encoder(query_tensor)\n",
    "\n",
    "        # Encode documents and move to device\n",
    "        doc_tensors = pad_sequence([torch.tensor(tokenizer.encode(doc), dtype=torch.long) for doc in documents], batch_first=True).to(device)\n",
    "        doc_vecs = doc_encoder(doc_tensors)\n",
    "\n",
    "        # Calculate similarity scores\n",
    "        scores = F.cosine_similarity(query_vec, doc_vecs)\n",
    "        top_indices = torch.argsort(scores, descending=True)\n",
    "        \n",
    "        # Convert results back to CPU for return (if needed)\n",
    "        results = [(documents[i], scores[i].item()) for i in top_indices]\n",
    "        \n",
    "        # Clear MPS cache after inference if available\n",
    "        if device.type == 'mps' and hasattr(torch.mps, 'empty_cache'):\n",
    "            torch.mps.empty_cache()\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea93713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training...\n",
      "  Batch 50/126365, Loss: 1.0012\n",
      "  Batch 100/126365, Loss: 0.9825\n"
     ]
    }
   ],
   "source": [
    "# --- Comprehensive Testing with Real Data ---\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def evaluate_retrieval(test_data, query_encoder, doc_encoder, tokenizer, k=10):\n",
    "    \"\"\"\n",
    "    Evaluate retrieval performance using real test data\n",
    "    \"\"\"\n",
    "    print(\"üîç COMPREHENSIVE RETRIEVAL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Group test data by query to get all relevant docs per query\n",
    "    query_to_docs = defaultdict(list)\n",
    "    for query, pos_doc, neg_doc in test_data[:100]:  # Sample 100 for speed\n",
    "        query_to_docs[query].extend([pos_doc, neg_doc])\n",
    "    \n",
    "    # Test multiple queries\n",
    "    sample_queries = list(query_to_docs.keys())[:5]  # Test 5 queries\n",
    "    \n",
    "    for i, query in enumerate(sample_queries):\n",
    "        print(f\"\\nüîé TEST QUERY {i+1}: {query[:100]}...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Get all documents for this query\n",
    "        documents = query_to_docs[query]\n",
    "        \n",
    "        # Add some random documents from other queries for harder test\n",
    "        other_docs = []\n",
    "        for other_query in random.sample(list(query_to_docs.keys()), 3):\n",
    "            if other_query != query:\n",
    "                other_docs.extend(query_to_docs[other_query][:2])\n",
    "        \n",
    "        all_documents = documents + other_docs\n",
    "        random.shuffle(all_documents)\n",
    "        \n",
    "        print(f\"üìö Searching through {len(all_documents)} documents...\")\n",
    "        \n",
    "        # Run search\n",
    "        results = search(query, all_documents, tokenizer, query_encoder, doc_encoder)\n",
    "        \n",
    "        print(f\"\\nüèÜ TOP {min(3, len(results))} RESULTS:\")\n",
    "        for j, (doc, score) in enumerate(results[:3]):\n",
    "            relevance = \"‚úÖ RELEVANT\" if doc in documents else \"‚ùå NOT RELEVANT\"\n",
    "            print(f\"{j+1}. Score: {score:.4f} {relevance}\")\n",
    "            print(f\"   Doc: {doc[:80]}...\")\n",
    "            print()\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "evaluate_retrieval(test_data, query_encoder, doc_encoder, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Automatic Model Saving ---\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create artifacts directory\n",
    "artifacts_dir = \"../artifacts\"\n",
    "os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "# Create timestamped run directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = os.path.join(artifacts_dir, f\"two_tower_run_{timestamp}\")\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üíæ Saving artifacts to: {run_dir}\")\n",
    "\n",
    "# Save model state dictionaries\n",
    "torch.save({\n",
    "    'query_encoder_state_dict': query_encoder.state_dict(),\n",
    "    'doc_encoder_state_dict': doc_encoder.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': config['EPOCHS'],\n",
    "    'final_loss': avg_loss\n",
    "}, os.path.join(run_dir, 'model_checkpoint.pth'))\n",
    "\n",
    "# Save model architectures (for easy loading later)\n",
    "torch.save(query_encoder, os.path.join(run_dir, 'query_encoder_full.pth'))\n",
    "torch.save(doc_encoder, os.path.join(run_dir, 'doc_encoder_full.pth'))\n",
    "\n",
    "# Save training configuration\n",
    "training_config = {\n",
    "    'model_config': {\n",
    "        'vocab_size': VOCAB_SIZE,\n",
    "        'embed_dim': EMBED_DIM,\n",
    "        'hidden_dim': config['HIDDEN_DIM'],\n",
    "        'margin': config['MARGIN']\n",
    "    },\n",
    "    'training_config': {\n",
    "        'epochs': config['EPOCHS'],\n",
    "        'batch_size': config['BATCH_SIZE'],\n",
    "        'learning_rate': config['LR'],\n",
    "        'device': str(device)\n",
    "    },\n",
    "    'data_config': {\n",
    "        'train_samples': len(train_data),\n",
    "        'val_samples': len(val_data),\n",
    "        'test_samples': len(test_data),\n",
    "        'total_triplets': len(train_data) + len(val_data) + len(test_data)\n",
    "    },\n",
    "    'training_results': {\n",
    "        'final_avg_loss': avg_loss\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_dir, 'training_config.json'), 'w') as f:\n",
    "    json.dump(training_config, f, indent=2)\n",
    "\n",
    "# Save tokenizer (copy the word2idx file or save the object)\n",
    "import shutil\n",
    "if os.path.exists(config['WORD_TO_IDX_PATH']):\n",
    "    shutil.copy2(config['WORD_TO_IDX_PATH'], os.path.join(run_dir, 'word_to_idx.pkl'))\n",
    "\n",
    "print(f\"‚úÖ Saved artifacts:\")\n",
    "print(f\"  üìÅ Directory: {run_dir}\")\n",
    "print(f\"  üß† Models: model_checkpoint.pth, *_encoder_full.pth\")\n",
    "print(f\"  ‚öôÔ∏è  Config: training_config.json\")\n",
    "print(f\"  üìù Tokenizer: word_to_idx.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1362865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MPS-Optimized Inference Function ---\n",
    "def search(query_text, documents, tokenizer, query_encoder, doc_encoder):\n",
    "    \"\"\"\n",
    "    Search function optimized for MPS (Apple Silicon GPU)\n",
    "    \"\"\"\n",
    "    # Get device from encoder\n",
    "    device = next(query_encoder.parameters()).device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Encode query and move to device\n",
    "        query_tensor = pad_sequence([torch.tensor(tokenizer.encode(query_text), dtype=torch.long)], batch_first=True).to(device)\n",
    "        query_vec = query_encoder(query_tensor)\n",
    "\n",
    "        # Encode documents and move to device\n",
    "        doc_tensors = pad_sequence([torch.tensor(tokenizer.encode(doc), dtype=torch.long) for doc in documents], batch_first=True).to(device)\n",
    "        doc_vecs = doc_encoder(doc_tensors)\n",
    "\n",
    "        # Calculate similarity scores\n",
    "        scores = F.cosine_similarity(query_vec, doc_vecs)\n",
    "        top_indices = torch.argsort(scores, descending=True)\n",
    "        \n",
    "        # Convert results back to CPU for return (if needed)\n",
    "        results = [(documents[i], scores[i].item()) for i in top_indices]\n",
    "        \n",
    "        # Clear MPS cache after inference if available\n",
    "        if device.type == 'mps' and hasattr(torch.mps, 'empty_cache'):\n",
    "            torch.mps.empty_cache()\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448019c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Comprehensive Testing with Real Data ---\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def evaluate_retrieval(test_data, query_encoder, doc_encoder, tokenizer, k=10):\n",
    "    \"\"\"\n",
    "    Evaluate retrieval performance using real test data\n",
    "    \"\"\"\n",
    "    print(\"üîç COMPREHENSIVE RETRIEVAL EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Group test data by query to get all relevant docs per query\n",
    "    query_to_docs = defaultdict(list)\n",
    "    for query, pos_doc, neg_doc in test_data[:100]:  # Sample 100 for speed\n",
    "        query_to_docs[query].extend([pos_doc, neg_doc])\n",
    "    \n",
    "    # Test multiple queries\n",
    "    sample_queries = list(query_to_docs.keys())[:5]  # Test 5 queries\n",
    "    \n",
    "    for i, query in enumerate(sample_queries):\n",
    "        print(f\"\\nüîé TEST QUERY {i+1}: {query[:100]}...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Get all documents for this query\n",
    "        documents = query_to_docs[query]\n",
    "        \n",
    "        # Add some random documents from other queries for harder test\n",
    "        other_docs = []\n",
    "        for other_query in random.sample(list(query_to_docs.keys()), 3):\n",
    "            if other_query != query:\n",
    "                other_docs.extend(query_to_docs[other_query][:2])\n",
    "        \n",
    "        all_documents = documents + other_docs\n",
    "        random.shuffle(all_documents)\n",
    "        \n",
    "        print(f\"üìö Searching through {len(all_documents)} documents...\")\n",
    "        \n",
    "        # Run search\n",
    "        results = search(query, all_documents, tokenizer, query_encoder, doc_encoder)\n",
    "        \n",
    "        print(f\"\\nüèÜ TOP {min(3, len(results))} RESULTS:\")\n",
    "        for j, (doc, score) in enumerate(results[:3]):\n",
    "            relevance = \"‚úÖ RELEVANT\" if doc in documents else \"‚ùå NOT RELEVANT\"\n",
    "            print(f\"{j+1}. Score: {score:.4f} {relevance}\")\n",
    "            print(f\"   Doc: {doc[:80]}...\")\n",
    "            print()\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "evaluate_retrieval(test_data, query_encoder, doc_encoder, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
