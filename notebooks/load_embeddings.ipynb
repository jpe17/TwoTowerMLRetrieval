{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load queries and documents and embed them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "📊 Sampling 10,000 samples...\n",
      "Sampled: 10000 samples\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'passages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m df_sample \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39mNUMBER_OF_SAMPLES, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampled: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_sample)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[43mpassages\u001b[49m])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Apply filtering AFTER sampling\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltering data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'passages' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastparquet\n",
    "\n",
    "NUMBER_OF_SAMPLES = 10000\n",
    "\n",
    "# Load and sample data FIRST\n",
    "print(\"Loading raw data...\")\n",
    "df = pd.read_parquet(\"../data/ms_marco_train.parquet\", engine='fastparquet')\n",
    "\n",
    "\n",
    "print(f\"📊 Sampling {NUMBER_OF_SAMPLES:,} samples...\")\n",
    "df_sample = df.sample(n=NUMBER_OF_SAMPLES, random_state=42).copy()\n",
    "print(f\"Sampled: {len(df_sample)} samples\")\n",
    "    \n",
    "\n",
    "# Apply filtering AFTER sampling\n",
    "print(\"Filtering data...\")\n",
    "df_filtered = df_sample[\n",
    "         (df_sample['query'].notna()) &\n",
    "         (df_sample['query_id'].notna()) &\n",
    "         (df_sample['query_type'].notna()) &\n",
    "         (df_sample['passages'].notna())\n",
    "     ].copy()\n",
    "\n",
    "print(f\"After filtering: {len(df_filtered)} samples\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create target variable ONCE\n",
    "print(\"Creating target variable...\")\n",
    "df_filtered['score_log'] = np.log1p(df_filtered['score'])\n",
    "\n",
    "# Verify consistency\n",
    "test_consistency = np.abs(df_filtered['score_log'] - np.log1p(df_filtered['score'])).max()\n",
    "print(f\"Target consistency check: {test_consistency:.10f}\")\n",
    "assert test_consistency < 1e-10, \"Target variable inconsistency detected!\"\n",
    "\n",
    "# Create advanced features\n",
    "df_filtered = create_advanced_features(df_filtered)\n",
    "\n",
    "# NO DATA AUGMENTATION - Remove this step that was causing corruption\n",
    "print(\"ℹ️ Skipping data augmentation to ensure data consistency\")\n",
    "\n",
    "# Load embeddings (skip if TITLE_EMB_DIM = 0)\n",
    "if config.TITLE_EMB_DIM > 0:\n",
    "    print(\"Loading embeddings...\")\n",
    "    word_to_idx, embeddings = load_glove_embeddings()\n",
    "    \n",
    "    if word_to_idx is None:\n",
    "        # Use zero embeddings if cache not available\n",
    "        print(\"Using zero embeddings for testing...\")\n",
    "        X_title_embeddings = np.zeros((len(df_filtered), config.TITLE_EMB_DIM), dtype=np.float32)\n",
    "    else:\n",
    "        print(\"Creating title embeddings...\")\n",
    "        X_title_embeddings = np.array([\n",
    "            title_to_embedding(title, word_to_idx, embeddings)\n",
    "            for title in df_filtered['title']\n",
    "        ], dtype=np.float32)\n",
    "else:\n",
    "    print(\"Skipping title embeddings (TITLE_EMB_DIM = 0)\")\n",
    "    X_title_embeddings = np.zeros((len(df_filtered), 0), dtype=np.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
